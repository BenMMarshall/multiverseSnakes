---
title: "Applying a Multiverse to Snake Habitat Selection"
author1: "Benjamin Michael Marshall*"
author2: "Alexander Bradley Duthie**"
affiliation1: "Biological and Environmental Sciences, Faculty of Natural Sciences, University of Stirling, Stirling, FK9 4LA, Scotland, UK"
affiliation2: "-"
corresponding1: "benjaminmichaelmarshall@gmail.com"
corresponding2: "alexander.duthie@stir.ac.uk"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    template: main.tex
    keep_tex: true
    highlight: monochrome
    fig_caption: true
    dev: pdf
  bookdown::html_document2:
    theme: yeti
    highlight: monochrome
    fig_caption: true
link-citations: yes
linkcolor: gray
bibliography: [multiverseSnakesPrereg_refs.bib, packages_refs.bib]
csl: peerj.csl
editor_options: 
  markdown: 
    wrap: sentence
abstract: abc
keywords: Movement ecology, step selection function, habitat preference, habitat selection, animal movement, multiverse, research choice, researcher degrees for freedom,
---

# Introduction

<!-- Science should be self correcting -->
<!-- Alberts et al 2015 -->

<!-- Self-correction can be more ephemeral, not limited to direct hard replications -->
<!-- Peterson, Panosky 2021 -->

<!-- reproducibility crisis -->
<!-- Baker 2016 -->

* Science should be self correcting

A key component of science is the continual reassessment of past work and findings.
Whether that takes the form of "integrative replications" or quasi-replications<!-- see peterson paper for definition check . Also add quasi-rep citation --> testing the edges of previous findings generalisability and retesting questions in different study systems, or as direct replications aiming to discover how exactly how reliable previous work is.

<!-- Direct quote from Peterson 2021 - "When replication in the normal course of integration does not provide clear signals of truth or falsity, researchers instead look for signs of robustness." -->

* Reassessments of old data have reveal inconsistencies

Reassessments and replications - regardless of their position on the direct-quasi continuum - can aid the formal and organic self-correcting process of science.
Initial findings set the stage for subsequent work, building momentum that can accelerate progress, but also be difficult to redirect if the initial impetus was misdirected <!-- thinking the progress papers, think it was by Brembs about early research that is underpowered starting trends that are hard to stop -->.
Therefore, checking and confirming results early is important; we can see this principle recognised in the peer review system itself.

Checking previous findings through replication can be come more difficult in systems with high task uncertainty. 
High task uncertainty systems –those that manifest high levels of uncontrollable stochasticity– may make direct diagnostic replications impractical or impossible, and quasi-replications weaker supporting evidence <!-- peterson pano 2021 is the paper for this stuff -->.
Ecological systems can be considered as generating high task uncertainty, with many interconnected elements, and when studying wild systems many of those elements are uncontrollable.
<!-- peterson pano 2021 has a bit about "task uncertainty" where high perfectly describes ecology and the hard to control system -->


* We can't always collect more data, rechecking old data and conclusions an (albeit not replaceable) alternative

With ecological systems, such complexity and the inability to control or reset an experiment makes the direct replications costly.
When studying wild animals with a level of direct intervention, repeating experiments/studies might be unethical due to the well-being costs.
When faced with limited options for direct replications, an alternative, albeit not a replacement, would be to re-examine existing datasets.
Pooling old and new datasets, and reanalysising them may provide insights into broader generalisations.

* Computational reproducibility is important, but sometimes new methods appear that might offer additionally insight or is more robust to data structural issues.
* methods impact results and therefore conclusions, we can see such impact in many analysts and multiverses

In some cases older data may have been collected/recorded in away that enables completely fresh analysis.
As methodologies develop, conceptualisations change, and computational power increases, new avenues for examining the same data may materialise.
As these new methods are developed and applied, we may see the conclusions based upon those data change.
There are a growing number of examples demonstrating that the analysis approach alone can alter the results.
These examples elegantly show the possible extent of technical uncertainty present in some systems <!-- peterson and pano term again, needs defining -->.

* movement ecology has seen such development in methods, can we check the conclusions remain the same

Not all disciplines have explored the sources of uncertainty in findings equally.
Prudence would push for examination of uncertainty in all its forms, in particular for fields that already tackle high levels of uncertainty originating from a wild study system.
Movement ecology could be argued to exemplify such a field.
Animals are complex, existing in complex wild ecosystems, with individuality and personality that frustrates replication and control while simultaneously requiring strict ethical limitations on interventionist study.
Movement ecology has also seized the opportunities presented by technological developments, enabling higher resolution tracking of animal movements (e.g., GPS tracking) and more sophisticated analysis that can integrate the high dimensional data (e.g., x-y coordinates, time, acceleration, individual, other covariates of interest).

Personality and the repeatability of behaviours presents a key component to the uncertainty when attempting to generalise.
However, here we turn to the technical uncertainty, the uncertainty originating from the research and how they approach the data.
Previous many analyst projects highlight the potential for analyst-side variation, and previous multiverse explorations of movement ecology methods highlight the variation potentially presented within a synthetic movement dataset.
Here we take the multiverse approach further by applying it to a number of real case studies with the aim of exploration whether different analysis approaches could/would have altered the final general conclusions.

<!-- ecology has high "task uncertainty" stemming from high "technical" and "strategic task uncertainty" - Peterson pano 2021 -->

<!-- Peterson pano 2021 has a great line that when task uncertainty is higher and more uncontrollable variables exists then integrative replications are more open to interpretation. -->

* as a case study, we re-examine the findings from __ snake movement studies that all describe a form of habitat selection

We selected a quartet of separate but connected movement ecology studies that attempt to disentangle the habitat selection exhibited by snakes in north-eastern Thailand.
All four cases focus on snakes that come into conflict with humans to some extent, either because of the risks poses from their venom (king cobra, Malayan krait, banded krait), or because of their appetite for domestic livestock (Burmese python).
In all cases the habitat selection results could be used to guide snake conservation efforts, as well as interventions into human behaviour to mitigate human-snake conflict.
With these general goals in mind, we re-examine the movement datasets using a multiverse of habitat selection analysis pathways to reveal whether the same data could lead to different conclusions.

<!-- devezer et al 2021 - reproducing the results doesn't mean that they are more likely correct - pg 10. So instead here we are exploring the likely that conclusions would change, an attempt to gauge uncertainty with a number of ~equally~ valid analysis methods -->

<!-- Direct quote from Peterson 2021 - "When replication in the normal course of integration does not provide clear signals of truth or falsity, researchers instead look for signs of robustness." -->

# Methods

## Study Location
<!-- NE Thailand -->
All four case studies occurred in northeastern Thailand, within Nakhon Ratchashima province.
<!-- SERS -->
Three case studies (king cobra, Burmese python, banded krait) were conducted within the Sakaerat Biosphere Reserve.
The reserve comprises of three zones of management: core, buffer, and transitional
The core is largely primary forest; the buffer surrounds the core and is comprised of forest regeneration efforts, whereas the transitional zone allows more development resulting in a mix of agriculture, settlements, and plantation forest.
Bisecting the transitional zone, and running adjacent to the protected forest areas is a four-lane highway connecting the city of Nakhon Ratchshima to Bangkok.
<!-- SUT University campus -->
The case study (Malayan krait) not in the Sakaerat Biosphere Reserve was undertaken nearer to Nakhon Ratchshima proper, on the Suranaree University of Technology.
The university campus is a mix of scrub forest, open lawn, university buildings, and homes.

<!-- enough detail? and double check the match the orignal papers -->

## Study Species

The papers below use distance from feature in the models, we could add an exploration of binary habitats too.
Overall simplify the models just to the habitats of interest.
The python paper has a contrasting grouping of what makes water habitats, do we need to explore alternative groupings of land use types - suspect that we don't but instead use the paper specific definitions (except for the 2018 paper because the number of habitat types is high and ill defined).

Any paper using SSF methods we should summarise to the population level to get an estimate we can plot alongside the multiverse answers.
Won't be a perfect comparison, but least on a similar scale.
So we can get a naive mean of SSF preference for given habitat, and in the case of the population ones we can just use that estimate + CIs.

Each species will get model ran on three landscape configurations:
- original, using whatever method/classification system used, but we will only extract the estimates of direct interest to the hypotheses. Model formula will include all habitat types. This will also provide a means of reproducing the original answers for direct comparison to the other estimates from other decisions pathways. 2018 doesn't have this, so will use 2020 LU data.
- targeted continuous, a distance to landscape feature approach but refined only to landscapes that matter (e.g., inverted distance to semi-nat vs inverted distance to everything else).
- targeted binary, simply hypothesised good habitat versus everything else.

### King Cobra
@Marshall2018; @marshall_no_2020
OPHA
2018 paper doesn't conclude a habitat preference, more focusing on the fact that they do not remain within the forest.
The methods are a major limitation in that regard. 
Best course of action is likely to look at semi-nat areas and forest, and examine the validity of both claims.
Using the results from the iSSF in figure 4 primarily, clear semi-nat preference that works for a clean re-testable hypo, forest preference can be additional motivation to make the 2018 paper worth exploring too.
Didn't actually implement any population level summary, but we are testing general conclusions here.
As the other papers have excluded individuals, what if we do the same here for the 2018 snakes, so we have something just targeting the 2020 paper and then something more general? Would make the targets pipeline more intuitive as all species would have this decision. 
Hypothesis 1: King Cobras show preference for semi-natural habitat
Hypothesis 2: King Cobras show preference for forest habitat


### Burmese Python
@smith_native_2021
PYBI
excluded an individual for the pop-level stuff - possible choice to explore?
Figure 4 shows the clear population pattern preferring water (water bodies and semi-nat areas). Figure 5 shows the preference on an individual level also.
Hypothesis: Burmese Pythons select for areas near water.


### Malayan Krait
@hodges_malayan_2022
BUCA
Had excluded individuals - one simply doesn't have enough data; the other should be included(?) but it remained in one habitat type - possible choice to explore?
Hypothesis: Malayan Kraits select for buildings, settlements, and natural areas.

### Banded Krait
@knierim_spatial_2019
BUFA
Need to see if we can get the LU data.
Hypothesis: Banded Kraits select for waterways and field edges.

# ``` {r openOptions}
# optionsCompleteList <- readRDS(here::here("data", "optionsCompleteList.rds"))
# ```

# Results

# Discussion

## Limitations

## Conclusions

# Acknowledgements

BMM was funded by the Natural Environment Research Council (NERC) via the IAPETUS2 Doctoral Training Partnership.

# Software availablity

In addition to packages already mentioned in the methods we also used the following.

We used *R* `r paste0("v.", version$major, ".", version$minor)` [@base] via *RStudio* v.2023.6.2.561 [@rstudio]. <!-- version has to be manually added because rstudioapi doesn't work in targets -->
We used *here* `r paste0("v.", packageVersion("here"))` [@here] and *qs* `r paste0("v.", packageVersion("qs"))` [@qs] to manage directory addresses and saved objects.

We used *raster* `r paste0("v.", packageVersion("raster"))` [@raster] and *RandomFields* `r paste0("v.", packageVersion("RandomFields"))` [@RandomFields] to aid landscape raster creation alongside NLMR `r paste0("v.", packageVersion("NLMR"))` [@NLMR].

We used *ggplot2* `r paste0("v.", packageVersion("ggplot2"))` for creating figures [@ggplot2], with the expansions: *patchwork* `r paste0("v.", packageVersion("patchwork"))` [@patchwork], *ggridges* `r paste0("v.", packageVersion("ggridges"))` [@ggridges], and *ggdist* `r paste0("v.", packageVersion("ggdist"))` [@ggdist].

We used *brms* `r paste0("v.", packageVersion("brms"))` [@brms] to run Bayesian models, with diagnostics generated used *bayesplot* `r paste0("v.", packageVersion("bayesplot"))` [@bayesplot], *tidybayes* `r paste0("v.", packageVersion("tidybayes"))` [@tidybayes], and *performance* `r paste0("v.", packageVersion("performance"))` [@performance].

We used the *dplyr* `r paste0("v.", packageVersion("dplyr"))` [@dplyr], *tibble* `r paste0("v.", packageVersion("tibble"))` [@tibble],
<!-- *reshape2* `r paste0("v.", packageVersion("reshape2"))` [@reshape2], -->
and *stringr* `r paste0("v.", packageVersion("stringr"))` [@stringr] packages for data manipulation.

We used *sp* `r paste0("v.", packageVersion("sp"))` [@sp], *move* `r paste0("v.", packageVersion("move"))` [@move] for manipulation of spatial data and estimation of space use not otherwise mentioned in the methods.

We used rmarkdown `r paste0("v.", packageVersion("rmarkdown"))` [@rmarkdown2023; @rmarkdown2018; @rmarkdown2020], bookdown `r paste0("v.", packageVersion("bookdown"))` [@bookdown2016; @R-bookdown], tinytex `r paste0("v.", packageVersion("tinytex"))` [@tinytex2019; @tinytex2023], and knitr `r paste0("v.", packageVersion("knitr"))` [@knitr2015; @knitr2014; @knitr2023] packages to generate type-set outputs.

We generated R package citations with the aid of *grateful* `r paste0("v.", packageVersion("grateful"))` [@grateful].

# Data availabilty

<!-- add zenodo archived snapshot of github -->

# Supplementary Material

# References
