---
title: "Applying a Multiverse to Snake Habitat Selection"
author1: "Benjamin Michael Marshall*"
author2: "Alexander Bradley Duthie**"
affiliation1: "Biological and Environmental Sciences, Faculty of Natural Sciences, University of Stirling, Stirling, FK9 4LA, Scotland, UK"
affiliation2: "-"
corresponding1: "benjaminmichaelmarshall@gmail.com"
corresponding2: "alexander.duthie@stir.ac.uk"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    template: main.tex
    keep_tex: true
    highlight: monochrome
    fig_caption: true
    dev: pdf
  bookdown::html_document2:
    theme: yeti
    highlight: monochrome
    fig_caption: true
link-citations: yes
linkcolor: gray
bibliography: [multiverseSnakesPrereg_refs.bib, packages_refs.bib]
csl: peerj.csl
editor_options: 
  markdown: 
    wrap: sentence
abstract: abc
keywords: Movement ecology, step selection function, habitat preference, habitat selection, animal movement, multiverse, research choice, researcher degrees for freedom,
---

# Introduction

<!-- Science should be self correcting -->
<!-- Alberts et al 2015 -->

<!-- Self-correction can be more ephemeral, not limited to direct hard replications -->
<!-- Peterson, Panosky 2021 -->

<!-- reproducibility crisis -->
<!-- Baker 2016 -->

* Science should be self correcting

A key component of science is the continual reassessment of past work and findings.
Whether that takes the form of "integrative replications" or quasi-replications<!-- see peterson paper for definition check . Also add quasi-rep citation --> testing the edges of previous findings generalisability and retesting questions in different study systems, or as direct replications aiming to discover how exactly how reliable previous work is.

<!-- Direct quote from Peterson 2021 - "When replication in the normal course of integration does not provide clear signals of truth or falsity, researchers instead look for signs of robustness." -->

* Reassessments of old data have reveal inconsistencies

Reassessments and replications - regardless of their position on the direct-quasi continuum - can aid the formal and organic self-correcting process of science.

Complex and difficult to control for ecological system (high task uncertainty) largely prohibit direct diagnostic replications.


* We can't always collect more data, rechecking old data and conclusions an (albeit not replaceable) alternative

<!-- peterson pano 2021 has a bit about "task uncertainty" where high perfectly describes ecology and the hard to control system -->

* Computational reproducibility is important, but sometimes new methods appear that might offer additionally insight or is more robust to data structural issues.

* methods impact results and therefore conclusions, we can see such impact in many analysts and multiverses

<!-- ecology has high "task uncertainty" stemming from high "technical" and "strategic task uncertainty" - Peterson pano 2021 -->

<!-- Peterson pano 2021 has a great line that when task uncertainty is higher and more uncontrollable variables exists then integrative replications are more open to interpretation. -->

* movement ecology has seen such development in methods, can we check the conclusions remain the same

* as a case study, we re-examine the findings from __ snake movement studies that all describe a form of habitat selection

<!-- devezer et al 2021 - reproducing the results doesn't mean that they are more likely correct - pg 10. So instead here we are exploring the likely that conclusions would change, an attempt to gauge uncertainty with a number of ~equally~ valid analysis methods -->

<!-- Direct quote from Peterson 2021 - "When replication in the normal course of integration does not provide clear signals of truth or falsity, researchers instead look for signs of robustness." -->

# Methods

## Study Location
* NE Thailand
* SERS
* SUT University campus

## Study Species

The papers below use distance from feature in the models, we could add an exploration of binary habitats too.
Overall simplify the models just to the habitats of interest.
The python paper has a contrasting grouping of what makes water habitats, do we need to explore alternative groupings of land use types - suspect that we don't but instead use the paper specific definitions (except for the 2018 paper because the number of habitat types is high and ill defined).

Any paper using SSF methods we should summarise to the population level to get an estimate we can plot alongside the multiverse answers.
Won't be a perfect comparison, but least on a similar scale.
So we can get a naive mean of SSF preference for given habitat, and in the case of the population ones we can just use that estimate + CIs.

Each species will get model ran on three landscape configurations:
- original, using whatever method/classification system used, but we will only extract the estimates of direct interest to the hypotheses. Model formula will include all habitat types. This will also provide a means of reproducing the original answers for direct comparison to the other estimates from other decisions pathways. 2018 doesn't have this, so will use 2020 LU data.
- targeted continuous, a distance to landscape feature approach but refined only to landscapes that matter (e.g., inverted distance to semi-nat vs inverted distance to everything else).
- targeted binary, simply hypothesised good habitat versus everything else.

### King Cobra
@Marshall2018; @marshall_no_2020
OPHA
2018 paper doesn't conclude a habitat preference, more focusing on the fact that they do not remain within the forest.
The methods are a major limitation in that regard. 
Best course of action is likely to look at semi-nat areas and forest, and examine the validity of both claims.
Using the results from the iSSF in figure 4 primarily, clear semi-nat preference that works for a clean re-testable hypo, forest preference can be additional motivation to make the 2018 paper worth exploring too.
Didn't actually implement any population level summary, but we are testing general conclusions here.
As the other papers have excluded individuals, what if we do the same here for the 2018 snakes, so we have something just targeting the 2020 paper and then something more general? Would make the targets pipeline more intuitive as all species would have this decision. 
Hypothesis 1: King Cobras show preference for semi-natural habitat
Hypothesis 2: King Cobras show preference for forest habitat


### Burmese Python
@smith_native_2021
PYBI
excluded an individual for the pop-level stuff - possible choice to explore?
Figure 4 shows the clear population pattern preferring water (water bodies and semi-nat areas). Figure 5 shows the preference on an individual level also.
Hypothesis: Burmese Pythons select for areas near water.


### Malayan Krait
@hodges_malayan_2022
BUCA
Had excluded individuals - one simply doesn't have enough data; the other should be included(?) but it remained in one habitat type - possible choice to explore?
Hypothesis: Malayan Kraits select for buildings, settlements, and natural areas.

### Banded Krait
@knierim_spatial_2019
BUFA
Need to see if we can get the LU data.
Hypothesis: Banded Kraits select for waterways and field edges.

# ``` {r openOptions}
# optionsCompleteList <- readRDS(here::here("data", "optionsCompleteList.rds"))
# ```

# Results

# Discussion

## Limitations

## Conclusions

# Acknowledgements

BMM was funded by the Natural Environment Research Council (NERC) via the IAPETUS2 Doctoral Training Partnership.

# Software availablity

In addition to packages already mentioned in the methods we also used the following.

We used *R* `r paste0("v.", version$major, ".", version$minor)` [@base] via *RStudio* v.2023.6.2.561 [@rstudio]. <!-- version has to be manually added because rstudioapi doesn't work in targets -->
We used *here* `r paste0("v.", packageVersion("here"))` [@here] and *qs* `r paste0("v.", packageVersion("qs"))` [@qs] to manage directory addresses and saved objects.

We used *raster* `r paste0("v.", packageVersion("raster"))` [@raster] and *RandomFields* `r paste0("v.", packageVersion("RandomFields"))` [@RandomFields] to aid landscape raster creation alongside NLMR `r paste0("v.", packageVersion("NLMR"))` [@NLMR].

We used *ggplot2* `r paste0("v.", packageVersion("ggplot2"))` for creating figures [@ggplot2], with the expansions: *patchwork* `r paste0("v.", packageVersion("patchwork"))` [@patchwork], *ggridges* `r paste0("v.", packageVersion("ggridges"))` [@ggridges], and *ggdist* `r paste0("v.", packageVersion("ggdist"))` [@ggdist].

We used *brms* `r paste0("v.", packageVersion("brms"))` [@brms] to run Bayesian models, with diagnostics generated used *bayesplot* `r paste0("v.", packageVersion("bayesplot"))` [@bayesplot], *tidybayes* `r paste0("v.", packageVersion("tidybayes"))` [@tidybayes], and *performance* `r paste0("v.", packageVersion("performance"))` [@performance].

We used the *dplyr* `r paste0("v.", packageVersion("dplyr"))` [@dplyr], *tibble* `r paste0("v.", packageVersion("tibble"))` [@tibble],
<!-- *reshape2* `r paste0("v.", packageVersion("reshape2"))` [@reshape2], -->
and *stringr* `r paste0("v.", packageVersion("stringr"))` [@stringr] packages for data manipulation.

We used *sp* `r paste0("v.", packageVersion("sp"))` [@sp], *move* `r paste0("v.", packageVersion("move"))` [@move] for manipulation of spatial data and estimation of space use not otherwise mentioned in the methods.

We used rmarkdown `r paste0("v.", packageVersion("rmarkdown"))` [@rmarkdown2023; @rmarkdown2018; @rmarkdown2020], bookdown `r paste0("v.", packageVersion("bookdown"))` [@bookdown2016; @R-bookdown], tinytex `r paste0("v.", packageVersion("tinytex"))` [@tinytex2019; @tinytex2023], and knitr `r paste0("v.", packageVersion("knitr"))` [@knitr2015; @knitr2014; @knitr2023] packages to generate type-set outputs.

We generated R package citations with the aid of *grateful* `r paste0("v.", packageVersion("grateful"))` [@grateful].

# Data availabilty

<!-- add zenodo archived snapshot of github -->

# Supplementary Material

# References
